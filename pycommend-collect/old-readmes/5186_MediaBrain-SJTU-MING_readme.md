

# æ˜åŒ» (MING)ï¼šä¸­æ–‡åŒ»ç–—é—®è¯Šå¤§æ¨¡å‹

<p align="center">
  <img src=".\img\bgimage.png" width=800px/>
</p>


<div align="center"><img src="https://img.shields.io/badge/Version-1.3--alpha-brightgreen"> <img src="https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg"> <img src="https://img.shields.io/badge/python-3.9+-blue.svg"></div>

## ğŸŒé¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å¼€æºäº†åŸºäºåŒ»ç–—æŒ‡ä»¤å¾®è°ƒçš„ä¸­æ–‡åŒ»ç–—é—®è¯Šæ¨¡å‹ï¼š**æ˜åŒ» (MING)**ã€‚ç›®å‰æ¨¡å‹çš„ä¸»è¦åŠŸèƒ½å¦‚ä¸‹ï¼š

<!DOCTYPE html>
<html>
<body>
<table style="width: 100%;">
  <tr style="border-collapse: collapse; border: transparent;">
      <td style="width: 50%; border-collapse: collapse;border: transparent;"><img src=".\img\demo1.gif" alt="demo1"/></td>
      <td style="width: 50%; border-collapse: collapse;border: transparent;"><img src=".\img\demo2.gif" alt="demo2"/></td>
  </tr>
  <tr style="border-collapse: collapse; border: transparent;">
      <td style="width: 50%; border-collapse: collapse;border: transparent;" ><div align="center"><strong>åŒ»ç–—é—®ç­”</strong>ï¼šå¯¹åŒ»ç–—é—®é¢˜è¿›è¡Œè§£ç­”ï¼Œå¯¹æ¡ˆä¾‹è¿›è¡Œåˆ†æã€‚</div></td>
      <td style="width: 50%; border-collapse: collapse;border: transparent;"><div align="center"><strong>æ™ºèƒ½é—®è¯Š</strong>ï¼šå¤šè½®é—®è¯Šåç»™å‡ºè¯Šæ–­ç»“æœå’Œå»ºè®®ã€‚</div></td>
  </tr>
</table>
</body>
</html>

## ğŸ“„ç›¸å…³è®ºæ–‡
* MING-MOEæŠ€æœ¯æŠ¥å‘Š: MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models with Sparse Mixture of Low-Rank Adapter Experts] [[paper](https://arxiv.org/pdf/2404.09027.pdf)]

* åŸºäºå¤šæ™ºèƒ½ä½“äº¤äº’çš„å¤§è¯­è¨€æ¨¡å‹å¤šè½®é—®è¯Šè‡ªåŠ¨è¯„ä¼°æ¡†æ¶: Automatic Interactive Evaluation for Large Language Models with State Aware Patient Simulator [[paper](https://arxiv.org/pdf/2403.08495.pdf)][[code](https://github.com/BlueZeros/Automatic_Interactive_Evaluation)]

* äºŒé˜¶æ®µè§£è€¦å­¦ä¹ çš„ä¸´åºŠå¤§æ¨¡å‹å¯¹é½æ–¹æ³•: MEDCARE: Advancing Medical LLMs through Decoupling Clinical Alignment and Knowledge Aggregation [[paper](https://arxiv.org/pdf/2406.17484v3)] [[code](https://github.com/BlueZeros/MedCare)]

* åŸºäºå·¥å…·è‡ªé€‚åº”å­¦ä¹ ä¸åæ€çš„åŒ»å­¦æ™ºèƒ½ä½“å’Œå¤šç»´åº¦è¯„ä¼°åŸºå‡†: ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents [[paper](https://arxiv.org/abs/2410.17657)] [[code](https://github.com/BlueZeros/ReflecTool)]

## ğŸ’«æ›´æ–°
* ğŸ”¥ [2024/04/14] å¼€æºäº†åŸºäºQwen1.5æŒ‡ä»¤å¾®è°ƒçš„ä¸“å®¶æ··åˆæ¨¡å‹MING-MOE

* [2024/03/14] å¼€æºäº†åŸºäºQwen1.5-1.8bæŒ‡ä»¤å¾®è°ƒçš„MING-1.8B

* [2023/07/25] å¼€æºäº†åŸºäºbloomz-7bæŒ‡ä»¤å¾®è°ƒçš„MING-7B

* [2023/07/25] MedicalGPT-zhæ›´åä¸º**MING**

  

##  ğŸ”¬å¼€æºæ¨¡å‹

<!DOCTYPE html>
<html>
<head>
</head>
<body>
<table style="width: 80%;">
  <tr>
      <td style="width: 20%;"><div align="center"><strong>æ¨¡å‹</strong></div></td>
      <td style="width: 20%;"><div align="center"><strong>åŸºåº§</strong></div></td>
      <td style="width: 30%;"><div align="center"><strong>HuggingFace</strong></div></td>
  </tr>
  
  <tr>
      <td><center>MING-7B</center></td>
      <td><center><a href="https://huggingface.co/bigscience/bloomz-7b1-mt">bloomz-7b1-mt</a></center></td>
      <td><center>ğŸ¤—<a href="https://huggingface.co/BlueZeros/MING-7B">MING-7B</a></center></td>
  </tr>

  <tr>
      <td><center>MING-1.8B</center></td>
      <td><center><a href="https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat">Qwen1.5-1.8B</a></center></td>
      <td><center>ğŸ¤—<a href="https://huggingface.co/BlueZeros/MING-1.8B">MING-1.8B</a></center></td>
  </tr>

  <tr>
      <td><center>MING-MOE-1.8B</center></td>
      <td><center><a href="https://huggingface.co/Qwen/Qwen1.5-1.8B-Chat">Qwen1.5-1.8B</a></center></td>
      <td><center>ğŸ¤—<a href="https://huggingface.co/BlueZeros/MING-MOE-1.8B">MING-MOE-1.8B</a></center></td>
  </tr>

  <tr>
      <td><center>MING-MOE-4B</center></td>
      <td><center><a href="https://huggingface.co/Qwen/Qwen1.5-4B-Chat">Qwen1.5-4B</a></center></td>
      <td><center>ğŸ¤—<a href="https://huggingface.co/BlueZeros/MING-MOE-4B">MING-MOE-4B</a></center></td>
  </tr>

  <tr>
      <td><center>MING-MOE-7B</center></td>
      <td><center><a href="https://huggingface.co/Qwen/Qwen1.5-7B-Chat">Qwen1.5-7B</a></center></td>
      <td><center>ğŸ¤—<a href="https://huggingface.co/BlueZeros/MING-MOE-7B">MING-MOE-7B</a></center></td>
  </tr>

  <tr>
      <td><center>MING-MOE-14B</center></td>
      <td><center><a href="https://huggingface.co/Qwen/Qwen1.5-14B-Chat">Qwen1.5-14B</a></center></td>
      <td><center>ğŸ¤—<a href="https://huggingface.co/BlueZeros/MING-MOE-14B">MING-MOE-14B</a></center></td>
  </tr>
</table>
</body>
</html>


## âš¡å¿«é€Ÿå¼€å§‹

1. é…ç½®ç¯å¢ƒï¼ˆæµ‹è¯•ç¯å¢ƒå¦‚ä¸‹ï¼Œå…·ä½“ç‰ˆæœ¬å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚é…ç½®ï¼‰

   * python==3.9.16
   * pytorch==2.0.1+cu117
   * peft==0.9.0

2. å®‰è£…é¡¹ç›®ä¾èµ– 

   ```bash
   git clone https://github.com/MediaBrain-SJTU/MING
   cd MING
   pip install -e .
   ```

2. ä¸‹è½½æ¨¡å‹å‚æ•°å¹¶è¿è¡Œï¼ˆè¦æ±‚å•å¡æ˜¾å­˜ >= 15Gï¼‰
    * MING-MOE
   ```bash
   CUDA_VISIBLE_DEVICES=0 python -m ming/serve/cli.py \
       --model_path {path_to_checkpoint} \ # æ¨¡å‹è·¯å¾„
       --model_base {path_to_base_model} \ # åŸºåº§æ¨¡å‹è·¯å¾„
       --max_new_token 3072 # è¾“å‡ºæœ€å¤§é•¿åº¦
   ```

   * MING-1.8B
   ```bash
   CUDA_VISIBLE_DEVICES=0 python -m ming/serve/cli.py \
       --model_path {path_to_checkpoint} \ # æ¨¡å‹è·¯å¾„
       --max_new_token 2048 # è¾“å‡ºæœ€å¤§é•¿åº¦
   ```

   * MING-7B
   ```bash
   CUDA_VISIBLE_DEVICES=0 python -m ming/serve/cli.py \
       --model_path {path_to_checkpoint} \ # æ¨¡å‹è·¯å¾„
       --conv_template bloom \ # prompt
       --max_new_token 512 \ # è¾“å‡ºæœ€å¤§é•¿åº¦
       --beam_size 3 \ # beam searchå®½åº¦
       --temperature 1.2 # é‡‡æ ·æ¸©åº¦
   ```
   
   * æ³¨ï¼šç”±äºtransformersåº“çš„é—®é¢˜ï¼Œå½“beam-size > 1æ—¶ï¼Œéœ€è¦æ»¡è¶³temperature>=1.0ï¼Œå¦åˆ™ä¼šæŠ¥é”™ã€‚

4. å‘½ä»¤è¡Œè¿è¡Œå®ä¾‹

   * å¯¹è¯æ”¯æŒå¤šè½®

   * å¯¹è¯ä¸­è¾“å…¥å…³é”®è¯ `new chat` èƒ½å¤Ÿå¼€å¯æ–°ä¸€è½®å¯¹è¯ã€‚


## ğŸ§­æµ‹è¯•æ ·ä¾‹
<p align="center">
  <img src=".\img\case1.png" width=800px/>
</p>

<p align="center">
  <img src=".\img\case2.png" width=800px/>
</p>



## ğŸª¶è´¡çŒ®

æœ¬é¡¹ç›®ç”±ä¸Šæµ·äº¤é€šå¤§å­¦æœªæ¥åª’ä½“ç½‘ç»œååŒåˆ›æ–°ä¸­å¿ƒå’Œä¸Šæµ·äººå·¥æ™ºèƒ½å®éªŒå®¤æ™ºæ…§åŒ»ç–—ä¸­å¿ƒåˆä½œç ”å‘ã€‚æ¨¡å‹æ•°æ®ç³»ç»Ÿä¸»è¦ç”±å»–è‚²ç”Ÿï¼Œæ±Ÿä¹¦æ´‹ï¼Œåˆ˜æ³“å‘ˆï¼Œå­Ÿæ˜±åŒå®Œæˆï¼ŒæŒ‡å¯¼æ•™å¸ˆä¸º[ç‹é’°](https://mediabrain.sjtu.edu.cn/yuwang/)å‰¯æ•™æˆã€‚



## å…è´£å£°æ˜

é¢„è®­ç»ƒæ¨¡å‹æ˜¯åŸºäºå¤§é‡è¯­æ–™åº“å’Œç®—æ³•æ¨¡å‹è¿›è¡Œè®­ç»ƒçš„ï¼Œå¹¶ä¸”åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¯èƒ½å­˜åœ¨åå·®ã€é”™è¯¯å’Œä¸å®Œæ•´çš„ä¿¡æ¯ã€‚å› æ­¤ï¼Œæœ¬é¡¹ç›®æä¾›çš„é¢„è®­ç»ƒæ¨¡å‹ä»…ä¾›å‚è€ƒå’Œç ”ç©¶ä½¿ç”¨ï¼Œå¹¶ä¸èƒ½ä¿è¯å…¶å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹äº§ç”Ÿçš„ç»“æœå¯èƒ½å­˜åœ¨è¯¯å·®å’Œåå·®ï¼Œä¸èƒ½ç”¨äºå®é™…åº”ç”¨æˆ–å†³ç­–ã€‚æœ¬é¡¹ç›®ä¸å¯¹ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ‰€äº§ç”Ÿçš„ç»“æœæ‰¿æ‹…ä»»ä½•è´£ä»»ï¼Œä¹Ÿä¸å¯¹å› ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ‰€äº§ç”Ÿçš„ä»»ä½•æŸå¤±æ‰¿æ‹…è´£ä»»ã€‚ä½¿ç”¨è€…åœ¨ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹æ—¶åº”è‡ªè¡Œæ‰¿æ‹…é£é™©å¹¶è¿›è¡Œè‡ªæˆ‘éªŒè¯ã€‚



## å¼•ç”¨

å¦‚æœä½ ä½¿ç”¨äº†æœ¬é¡¹ç›®çš„æ•°æ®æˆ–è€…ä»£ç ï¼Œè¯·å£°æ˜å¼•ç”¨

```latex
@article{liao2024ming,
  title={MING-MOE: Enhancing Medical Multi-Task Learning in Large Language Models with Sparse Mixture of Low-Rank Adapter Experts},
  author={Liao, Yusheng and Jiang, Shuyang and Wang, Yu and Wang, Yanfeng},
  journal={arXiv preprint arXiv:2404.09027},
  year={2024}
}
```

```latex
@misc{MING,
  author={Yusheng Liao, Yutong Meng, Hongcheng Liu, Yu Wang, Yanfeng Wang},
  title = {æ˜åŒ» (MING)ï¼šä¸­æ–‡åŒ»ç–—é—®è¯Šå¤§æ¨¡å‹},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/MediaBrain-SJTU/MING}},
}
```

